1.1 Sí que se pueden lanzar más threads que cores tenga el sistema. Puede tener sentido hacerlo para aprovechar los tiempos de bloqueo (E/S), pero no se va a poder ejecutar todos de manera paralela.
1.2 Suponiendo que los hilos son "workers" que se reparten una misma tarea, el número de hilos debería ser proporcional al número de núcleos. Por lo tanto debería haber más hilos en un clúster que en un ordenador personal.
1.3 Para las variables privadas OpenMP asigna posiciones de memoria diferentes a cada hilo. 
1.4 El valor de la variable privada no está inicializado.
1.5 El valor de la variable se pierde.
1.6 No, las variables públicas se comparten entre hilos. Su valor al iniciar la región paralela es el valor que tenía asignado previamente. Al terminar la región paralela no se pierde su valor.

2.1 El resultado correcto es el del archivo "pescalar_par2". En el primero hay una condición de carrera, ya que los diferentes hilos van pisándose los valores de las sumas parciales. Por esto el valor obtenido en el primer ejecutable es sistemáticamente menor al obtenido en el segundo, además de ser fluctuante según la ejecución (el segundo ejecutable no lo es porque los valores generados son pseudoaleatorios y la semilla es igual en las diferentes ejecuciones). 2222222
2.3 | 2.4 | 2.5 En el tests que hemos realizado todos los tamaños son lo suficientemente grandes como para que el trabajo adicional de crear los nuevos hilos sea insignificante en comparación al beneficio obtenido. Podría no compensar si los tamaños fuesen muy pequeños y no se rentabilizase la creación de hilos, si el procesador estuviese muy saturado y no dispusiese de núcleos ociosos o si los problemas generados por la paralelización del trabajo (procesos muy dependientes entre sí) superasen los beneficios obtenidos.
2.6 Siempre es así.
2.7 Como ya se ha mencionado, con vectores muy pequeños el trabajo que supone crear los hilos tendría un impacto mucho mayor. Con vectores muy grandes seguirá funcionando en torno a n veces más rápido una paralelización en n núcleos.

3.1 El que peor rendimiento tiene es el que paraleliza el bucle más interno. El motivo principal es que es necesaria una reducción posterior, ya que los diferentes hilos modifican el mismo elemento de la matriz.
3.2 El que mejor rendimiento tiene (con poca diferencia) es el más externo. Su ventaja respecto al intermedio es que los hilos solo deben "sincronizarse" al finalizar todo el proceso y no en cada iteración del bucle externo. Por otro lado tiene la desventaja de que, al repartir bloques de trabajo de mayor tamaño, es más probable que el resultado tenga que esperar a que unos pocos hilos acaben su parte, mientras que el resto podrían haber terminado.

4.1 El programa utiliza cien mil rectángulos para realizar el cómputo
4.2 La principal diferencia entre los dos programas consiste en que la versión 4 utiliza una variable auxiliar para almacenar los resultados parciales de cada hilo, mientras que en la primera, al estar modificando todos los hilos regiones cercanas de memoria, el funcionamiento de la caché ralentiza la ejecución, produciendose false sharing.
4.3 El resultado calculado es el mismo, pero la versión en la que se produce false sharing resulta significativamente más lenta que en la que no se produce (gracias a que se guarda cada hilo sus resultados parciales).
4.4 En las versiones 3 y 4 se observa una mejoría en el rendimiento en comparación con la versión 1, ya que la versión 2 hace que las sumas parciales sean privadas para cada proceso (evitando el false sharing) y la versión 3 se vale del padding para generar espacio entre los valores de las sumas parciales, de manera que las regiones de memoria son lo suficientemente distantes como para evitar el false sharing.
4.5 El tiempo de ejecución es menor cuanto menor es el tamaño de datasz, ya que de esta manera el padding es mayor y por lo tanto el efecto del false sharing es menos acusado.